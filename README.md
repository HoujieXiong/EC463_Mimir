# Mimir
_Trust at First Sight!_ <br>

## Description
Our wearable device aims to assist the visually impaired with real-time guidance
regarding their surroundings. Utilizing a camera, speaker, microphone and artificial intelligence, the device will be able to recognize people, obstacles, and the environment and dictate the information back to the user. We will also incorporate cloud computing to assist in our computational power without sacrificing form factor. Through a focus on comfort and functionality, we aim to empower visually impaired individuals to be able to navigate the world more easily utilizing an intuitive and unobtrusive design. <br>

### Team
Louis Jimenez-Hernandez (louisjh@bu.edu) <br>
Heather Li (hli9753@bu.edu) <br>
Dylan Ramdhan (dylram01@bu.edu) <br>
Houjie Xiong (xhj@bu.edu) <br>


### Current State of Mimir
text <br>


### Future Iterations of Mimir
text <br>


### Links
[ðŸ“„ View User Manual](./README-files/Users-Manual.pdf)
[ðŸ’» View Mimir's Software Components](./README-files/SOFTWARE.md)
[ðŸ”Œ View Mimir's Hardware Components](./README-files/HARDWARE.md)