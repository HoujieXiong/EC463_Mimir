# Mimir

<p align="center">
<img src="./README-files/Mimir_logo.png" width="50%">
</p>

<p align="center">
Trust at First Sight! <br>
</p>

### Description
Our wearable device aims to assist the visually impaired with real-time guidance
regarding their surroundings. Utilizing a camera, speaker, microphone and artificial intelligence, the device will be able to recognize people, obstacles, and the environment and dictate the information back to the user. We will also incorporate cloud computing to assist in our computational power without sacrificing form factor. Through a focus on comfort and functionality, we aim to empower visually impaired individuals to be able to navigate the world more easily utilizing an intuitive and unobtrusive design. <br>

### Team
Louis Jimenez-Hernandez (louisjh@bu.edu) <br>
Heather Li (hli9753@bu.edu) <br>
Dylan Ramdhan (dylram01@bu.edu) <br>
Houjie Xiong (xhj@bu.edu) <br>


### Current State of Mimir
text <br>


### Future Iterations of Mimir
In future iterations we tend to implement newer features to allow more interactive components that can expand our goals of providing visually impaired individuals more accessibility while performing other assistants in daily duties, such as laundry, driving, and other personal care to name a few. Mimir has encapsulates future potential in providing better care for those of the visually impaired individuals, more independency and opportunities to live a better quality of life. <br>


### Links
[ðŸ“„ View User's Manual](./README-files/Users-Manual.pdf) <br>
[ðŸ“‹ View Test Plans]() <br>
[ðŸ“‘ View Test Reports]() <br>
[ðŸ’» View Mimir's Software Components](./README-files/SOFTWARE.md) <br>
[ðŸ”Œ View Mimir's Hardware Components](./README-files/HARDWARE.md)